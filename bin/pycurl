#!/usr/bin/env python

'''
Basically, this is nothing but

.. code-block::bash

   $ curl ${CURL_ARGS} | python -mjson.tool | pygmentize -l json  # example for JSON content type

only in python. I don't want to battle bash on reinterpreting
quoted cURL args when trying to wrap this into a script
or aliasing it.

No cli help whatsoever, used only as another tool for quick
and dirty interacting with the server backend via REST API.

Example usage:

.. code-block::bash

   $ pycurl -i -H "Authorization: JWT my-token" http://localhost:8000/api/v2/projects/1/testcases/
   $ pycurl -X PATCH -H "Authorization: JWT my-token" -d '{"name": "foo"}' http://localhost:8000/api/v2/projects/1/testcases/1/

The header `Content-Type: application/json` will be inserted
automatically if not passed via cli.

Disclaimer: no warranty whatsoever, use at your own risk.

TODO:
 * replace mimicking ``pygmentize`` cli call with calling the appropriate pygments function
 * proper content type checks by parsing returned headers

For quick testing:

.. code-block::bash

   $ curl http://eu.httpbin.org/get     # json
   $ curl http://eu.httpbin.org/xml     # xml
   $ curl http://eu.httpbin.org/html    # html

'''


from __future__ import absolute_import, division, print_function

import argparse
import itertools
import json
import re
import subprocess
import sys

import bs4
import lxml.etree
import pygments.cmdline


#----------------------------------------------------------------------
def main():
    ''''''
    (_, args) = argparse.ArgumentParser().parse_known_args()
    print_headers = any(arg in args for arg in ['-i', '--include'])

    try:
        out = subprocess.check_output(['curl'] + args + ['--include'])
        matcher = re.compile(b'charset=(.*)$', re.MULTILINE)
        enc = next(item.group(1) for item in itertools.islice(re.finditer(matcher, out), 1))
        out = out.decode(encoding=enc.decode())
    except subprocess.CalledProcessError:
        return 1
    except StopIteration:  # charset information not found or present, try default encoding
        out = out.decode()

    (headers, payload) = out.strip().split('\r\n\r\n', 1)

    if payload.strip().startswith('{'):
        lexer = 'json'
        payload_formatted = json.dumps(
            json.loads(payload), indent=4
        )
    elif '<html' in payload.lower():
        lexer = 'html'
        payload_formatted = bs4.BeautifulSoup(
            payload, 'html.parser'
        ).prettify()
    else:  # assume xml
        lexer = 'xml'
        payload_formatted = lxml.etree.tostring(
            lxml.etree.fromstring(
                payload.encode('utf-8'),
                parser=lxml.etree.XMLParser(encoding='utf-8')
            ),
            pretty_print=True,
            method='xml'
        ).decode('utf-8')

    if print_headers:
        print(headers + '\n')

    cmd = ['pygmentize', '-l', lexer]
    p = subprocess.Popen(
        cmd, stdin=subprocess.PIPE, shell=False
    ).communicate(input=payload_formatted.encode('utf-8'))
    return 0


if __name__ == '__main__':
    sys.exit(main())
